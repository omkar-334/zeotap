{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "customers_df = pd.read_csv('data/Customers.csv')\n",
    "products_df = pd.read_csv('data/Products.csv')\n",
    "transactions_df = pd.read_csv('data/Transactions.csv')\n",
    "\n",
    "# á¹‚erge all the three datasets and remove the common column\n",
    "data = transactions_df.merge(customers_df, on='CustomerID').merge(products_df, on='ProductID')\n",
    "data = data.rename(columns={'Price_x':\"Price\"}).drop('Price_y', axis=1)\n",
    "\n",
    "customers = customers_df['CustomerID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to calculate the perecentage of category bought by each individual customer.\n",
    "\n",
    "def calculate_category_preferences(data):\n",
    "    category_quantities = data.groupby(['CustomerID', 'Category'])['Quantity'].sum().reset_index()\n",
    "    customer_totals = data.groupby('CustomerID')['Quantity'].sum().reset_index()\n",
    "    categories, customers = data['Category'].unique(), data['CustomerID'].unique()\n",
    "    \n",
    "    category_dict = {}\n",
    "    for customer in customers:\n",
    "        customer_data = category_quantities[category_quantities['CustomerID'] == customer]\n",
    "        customer_total = customer_totals[customer_totals['CustomerID'] == customer]['Quantity'].iloc[0]\n",
    "        \n",
    "        category_dict[customer] = {}\n",
    "        for category in categories:\n",
    "            category_row = customer_data[customer_data['Category'] == category]\n",
    "            \n",
    "            quantity = category_row['Quantity'].iloc[0] if len(category_row) else 0\n",
    "\n",
    "            category_dict[customer][category] = quantity / customer_total\n",
    "\n",
    "    return pd.DataFrame.from_dict(category_dict, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    \n",
    "    # First create customer features by aggregation\n",
    "    customer_features = data.groupby('CustomerID').agg({\n",
    "        'TotalValue': ['mean', 'sum'],  #Avg spend and total spend\n",
    "        'Quantity': ['mean', 'sum'],    #Avg quantity and total quantitty\n",
    "        'TransactionID': 'count',       #Total txns\n",
    "        'TransactionDate': [\n",
    "            lambda x: (pd.to_datetime('today') - pd.to_datetime(x.max())).days,  #Time since last purchase\n",
    "            lambda x: (pd.to_datetime(x.max()) - pd.to_datetime(x.min())).days   #Purchase range\n",
    "        ]\n",
    "    }).reset_index()\n",
    "\n",
    "    numerical_cols = [\n",
    "        'avg_order_value', 'total_spend', 'avg_quantity',\n",
    "        'total_quantity', 'transaction_count', 'days_since_last',\n",
    "        'purchase_timespan'\n",
    "    ]\n",
    "    customer_features.columns = ['CustomerID', *numerical_cols]\n",
    "    \n",
    "    # Extract categorical features\n",
    "    category_preferences = calculate_category_preferences(data)\n",
    "\n",
    "    #  Get regional features by one-hot encoding.\n",
    "    region_dummies = pd.get_dummies(\n",
    "        customers_df[customers_df['CustomerID'].isin(customer_features['CustomerID'])]['Region']\n",
    "    )\n",
    "    region_features = torch.tensor(\n",
    "        region_dummies.values,\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # Convert all features to tensor format and normalize the numerical features.\n",
    "    #  (Z score normalization) - converts all features into the same scale.\n",
    "    numerical_features = torch.tensor(\n",
    "    customer_features[numerical_cols].values, \n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    numerical_features = (numerical_features - numerical_features.mean(dim=0)) / (\n",
    "        numerical_features.std(dim=0) + 1e-7\n",
    "    )\n",
    "\n",
    "    category_features = torch.tensor(\n",
    "        category_preferences.values, \n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # Concat all 4 feature arrays into a single array\n",
    "    all_features = torch.cat([\n",
    "        numerical_features, \n",
    "        category_features,   \n",
    "        region_features     \n",
    "    ], dim=1)\n",
    "    \n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A basic neural network consisting of 2 linear layers.\n",
    "class SimilarityModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features):\n",
    "        return F.normalize(self.layers(features), p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extract_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimilarityModel(input_dim=features.shape[1])\n",
    "    \n",
    "with torch.no_grad():\n",
    "    embeddings = model(features)\n",
    "\n",
    "similarity_matrix = torch.mm(embeddings, embeddings.t())\n",
    "_, top_indices = torch.topk(similarity_matrix, k=4, dim=1)\n",
    "# here top k = 4 returns top 4 similar results (1 is self, and 3 are the others)\n",
    "\n",
    "# get top similarities for first 20 customers.\n",
    "lookalike_results = {}\n",
    "for i in range(20):\n",
    "    similar_indices = top_indices[i][1:4].numpy()  # Skip self, get next 3\n",
    "    similarities = similarity_matrix[i][similar_indices].numpy()\n",
    "    \n",
    "    similar_customers = [\n",
    "        {'CustomerID': customers[idx], 'Score': float(score)}\n",
    "        for idx, score in zip(similar_indices, similarities)\n",
    "    ]\n",
    "    lookalike_results[customers[i]] = similar_customers\n",
    "\n",
    "lookalike_df = pd.DataFrame({\n",
    "    'CustomerID': lookalike_results.keys(),\n",
    "    'Lookalikes': lookalike_results.values()\n",
    "})\n",
    "lookalike_df.to_csv('Lookaliketorch.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
